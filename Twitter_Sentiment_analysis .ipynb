{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size =6, color=\"marquee\"> Twitter US Airline Sentiment Classification using \n",
    "    navie bayes generative classifier </font></center>\n",
    "\n",
    "  https://www.kaggle.com/crowdflower/twitter-airline-sentiment\n",
    "  \n",
    "  Data can be downloaded from the following link. You have to login to the kaggle site to get access to the data.\n",
    "Unzip the data in folder where notebook is running. There should be a file called **Tweet.csv**\n",
    "\n",
    "https://www.kaggle.com/crowdflower/twitter-airline-sentiment/downloads/twitter-airline-sentiment.zip/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://images.unsplash.com/photo-1529990131237-cfa5ce9517b6?ixlib=rb-1.2.1&auto=format&fit=crop&w=1949&q=80\"  width=\"900\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem statement:** classify sentiment based on text as positive or negative* using **naive bayes** in supervised machine setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd # for data analysis\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install scikit-learn\n",
    "#! pip install gensim\n",
    "#!pip install -U setuptools\n",
    "#!pip install pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_url = 'Tweets.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!head -n 10  Tweets.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly it is a comma separated csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>570300767074181121</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:33 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "5  570300767074181121          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "5     Can't Tell                     0.6842  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "5                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "5  @VirginAmerica seriously would pay $30 a fligh...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  \n",
       "5  2015-02-24 11:14:33 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_sentiment_df = pd.read_csv('Tweets.csv')\n",
    "airlines_sentiment_df.head(6) # there are other functions like tail and sample to check record in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting observation with positive and negative sentiment only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_sentiment_df = airlines_sentiment_df[airlines_sentiment_df.airline_sentiment.isin(['positive', 'negative'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>570000287080951808</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Cancelled Flight</td>\n",
       "      <td>0.6566</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MirandaAtx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Exhausted &amp;amp; frustrated! Link to a ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 15:20:33 -0800</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14628</th>\n",
       "      <td>569588651925098496</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jlhalldc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. “@AmericanAir: @jlhalldc Customer R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 12:04:51 -0800</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>568014845062332416</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Late Flight</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rjburnsva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue #1408 IAD to JFK still hasn't boarded...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 03:51:06 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12252</th>\n",
       "      <td>570250940290342914</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6866</td>\n",
       "      <td>Lost Luggage</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kukirani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir hi we have lost and found solutio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 07:56:33 -0800</td>\n",
       "      <td>Worldwide</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13866</th>\n",
       "      <td>569699154965827584</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>Flight Booking Problems</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kathyjazztx</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir and it gets better...other passen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 19:23:57 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>569206183283843072</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tweeter_mom_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir My husband is responding to him ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-21 10:45:04 -0800</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8648</th>\n",
       "      <td>568083588308197376</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Late Flight</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>duendecillita</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue you are missing the point. The flight...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 08:24:16 -0800</td>\n",
       "      <td>NYC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>569158165176164353</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Late Flight</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bsjuts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir where are our pilots? Plane is h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-21 07:34:15 -0800</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>568637541513089024</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.9220</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.4513</td>\n",
       "      <td>United</td>\n",
       "      <td>negative</td>\n",
       "      <td>Mosborne13</td>\n",
       "      <td>Cancelled Flight\\nCustomer Service Issue</td>\n",
       "      <td>0</td>\n",
       "      <td>@united rebooked 24 hours after original fligh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 21:05:29 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>568083179023650818</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.3556</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iamWalkerR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica kinda sucked my earphone jack d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 08:22:39 -0800</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "939    570000287080951808          negative                        1.0000   \n",
       "14628  569588651925098496          positive                        1.0000   \n",
       "8691   568014845062332416          negative                        1.0000   \n",
       "12252  570250940290342914          negative                        0.6866   \n",
       "13866  569699154965827584          negative                        0.6765   \n",
       "5308   569206183283843072          negative                        0.6500   \n",
       "8648   568083588308197376          negative                        1.0000   \n",
       "5379   569158165176164353          negative                        1.0000   \n",
       "3149   568637541513089024          negative                        0.9220   \n",
       "433    568083179023650818          negative                        1.0000   \n",
       "\n",
       "                negativereason  negativereason_confidence         airline  \\\n",
       "939           Cancelled Flight                     0.6566          United   \n",
       "14628                      NaN                        NaN        American   \n",
       "8691               Late Flight                     1.0000           Delta   \n",
       "12252             Lost Luggage                     0.3520        American   \n",
       "13866  Flight Booking Problems                     0.6765        American   \n",
       "5308                Can't Tell                     0.3609       Southwest   \n",
       "8648               Late Flight                     1.0000           Delta   \n",
       "5379               Late Flight                     1.0000       Southwest   \n",
       "3149    Customer Service Issue                     0.4513          United   \n",
       "433                 Bad Flight                     0.3556  Virgin America   \n",
       "\n",
       "      airline_sentiment_gold           name  \\\n",
       "939                      NaN     MirandaAtx   \n",
       "14628                    NaN       jlhalldc   \n",
       "8691                     NaN      rjburnsva   \n",
       "12252                    NaN       Kukirani   \n",
       "13866                    NaN    kathyjazztx   \n",
       "5308                     NaN   Tweeter_mom_   \n",
       "8648                     NaN  duendecillita   \n",
       "5379                     NaN         bsjuts   \n",
       "3149                negative     Mosborne13   \n",
       "433                      NaN     iamWalkerR   \n",
       "\n",
       "                            negativereason_gold  retweet_count  \\\n",
       "939                                         NaN              0   \n",
       "14628                                       NaN              0   \n",
       "8691                                        NaN              0   \n",
       "12252                                       NaN              0   \n",
       "13866                                       NaN              0   \n",
       "5308                                        NaN              0   \n",
       "8648                                        NaN              0   \n",
       "5379                                        NaN              0   \n",
       "3149   Cancelled Flight\\nCustomer Service Issue              0   \n",
       "433                                         NaN              0   \n",
       "\n",
       "                                                    text tweet_coord  \\\n",
       "939    @united Exhausted &amp; frustrated! Link to a ...         NaN   \n",
       "14628  Thank you. “@AmericanAir: @jlhalldc Customer R...         NaN   \n",
       "8691   @JetBlue #1408 IAD to JFK still hasn't boarded...         NaN   \n",
       "12252  @AmericanAir hi we have lost and found solutio...         NaN   \n",
       "13866  @AmericanAir and it gets better...other passen...         NaN   \n",
       "5308   @SouthwestAir My husband is responding to him ...         NaN   \n",
       "8648   @JetBlue you are missing the point. The flight...         NaN   \n",
       "5379   @SouthwestAir where are our pilots? Plane is h...         NaN   \n",
       "3149   @united rebooked 24 hours after original fligh...         NaN   \n",
       "433    @VirginAmerica kinda sucked my earphone jack d...         NaN   \n",
       "\n",
       "                   tweet_created  tweet_location               user_timezone  \n",
       "939    2015-02-23 15:20:33 -0800     Houston, TX  Central Time (US & Canada)  \n",
       "14628  2015-02-22 12:04:51 -0800  Washington, DC  Eastern Time (US & Canada)  \n",
       "8691   2015-02-18 03:51:06 -0800             NaN  Eastern Time (US & Canada)  \n",
       "12252  2015-02-24 07:56:33 -0800       Worldwide                         NaN  \n",
       "13866  2015-02-22 19:23:57 -0800             NaN                         NaN  \n",
       "5308   2015-02-21 10:45:04 -0800         Florida  Eastern Time (US & Canada)  \n",
       "8648   2015-02-18 08:24:16 -0800             NYC  Eastern Time (US & Canada)  \n",
       "5379   2015-02-21 07:34:15 -0800       Nebraska   Central Time (US & Canada)  \n",
       "3149   2015-02-19 21:05:29 -0800             NaN  Central Time (US & Canada)  \n",
       "433    2015-02-18 08:22:39 -0800    New York, NY  Central Time (US & Canada)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_sentiment_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
       "       'negativereason', 'negativereason_confidence', 'airline',\n",
       "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
       "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_sentiment_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting only airline_sentiment and text filed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_sentiment_df = airlines_sentiment_df[['airline_sentiment', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing...\n",
       "5          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
       "6          positive  @VirginAmerica yes, nearly every time I fly VX..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is my  data set $\\mathcal{D} = \\{({x_i}, y_i)\\}_{i=1}^{N=5574}$ $x_i$ is text field and $y_i$ is airlines_sentiment(positive or negative)**. Using using this I will train(learn parameters $\\theta$ of a models(Naive bayes, Discriminant anlaysis based etc.)) and use trained model to classify new text as positive or negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment    object\n",
       "text                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_sentiment_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment    0\n",
       "text                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_sentiment_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset doesn't contain any nan and  looks clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting text to vectors(feature)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some [lemmatization](https://en.wikipedia.org/wiki/Lemmatisation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing...\n",
       "5          negative  @VirginAmerica seriously would pay $30 a fligh...\n",
       "6          positive  @VirginAmerica yes, nearly every time I fly VX..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airlines_sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'machine/NN', b'learn/VB']\n"
     ]
    }
   ],
   "source": [
    "try :lemmatize(\"Hi Machine learning\")\n",
    "except :pass\n",
    "print(lemmatize(\"Hi Machine learning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine', 'learn']\n"
     ]
    }
   ],
   "source": [
    "lemmatized_out =[wd.decode('utf-8').split('/')[0] for wd in lemmatize(\"Hi Machine learning\")]\n",
    "print(lemmatized_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessed_messages= airlines_sentiment_df.text.apply(lambda text: [wd.decode('utf-8').split('/')[0] for wd in lemmatize(text)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    [virginamerica, ve, add, commercial, experienc...\n",
       "3    [virginamerica, really, aggressive, blast, obn...\n",
       "4             [virginamerica, really, big, bad, thing]\n",
       "5    [virginamerica, seriously, pay, flight, seat, ...\n",
       "6    [virginamerica, yes, nearly, time, fly, vx, ea...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_labels = airlines_sentiment_df.airline_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning the data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training X (9232,) and train Y (9232,)\n",
      "Shape of test X (2309,) and test Y (2309,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_messages, test_messages, training_labels, test_labels = train_test_split(preprocessed_messages,\n",
    "                                                                                 messages_labels,\n",
    "                                                                                test_size= .2,random_state=0,\n",
    "                                                                                 stratify= messages_labels)\n",
    "print('Shape of training X {} and train Y {}'.format(training_messages.shape, training_labels.shape))\n",
    "print('Shape of test X {} and test Y {}'.format(test_messages.shape, test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_word = set()\n",
    "\n",
    "for message in training_messages:\n",
    "        unique_word.update(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many words in vocabulary\n",
    "num_unique_words = len(unique_word)\n",
    "num_unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some **feature engineering**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first  build a default dictionary to assign each word a unique location in the feature vector\n",
    "from collections import defaultdict, Counter\n",
    "word_to_index_dict = defaultdict(int)\n",
    "for index , word in enumerate(unique_word):\n",
    "    word_to_index_dict[word] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a reverse dictionary  for mapping index to word. It will help in debugging etc.\n",
    "index_to_word_dict = { value:key  for key, value in word_to_index_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9232,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_messages = training_messages.shape\n",
    "num_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a numpy integer matrix of **num_messages X num_unique_words**, initialized with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9232, 8192)\n"
     ]
    }
   ],
   "source": [
    "training_X = np.zeros((len(training_messages), len(unique_word)), dtype=int)\n",
    "print(training_X.shape)\n",
    "test_X = np.zeros((len(test_messages), len(unique_word)), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature(text, word_to_index_dict):\n",
    "    feature = np.zeros((len(word_to_index_dict),), dtype=int)\n",
    "    word_freq =  Counter(text)\n",
    "    # setting the word count in text_no row of text_features\n",
    "    for word, freq in word_freq.items():\n",
    "        if word in word_to_index_dict:\n",
    "            index_of_word = word_to_index_dict[word]\n",
    "            feature[index_of_word] = freq\n",
    "    return feature        \n",
    "for text_no, text in enumerate(training_messages):\n",
    "    training_X[text_no] = build_feature(text, word_to_index_dict)\n",
    "    \n",
    "for text_no, text in enumerate(test_messages):\n",
    "    test_X[text_no] = build_feature(text, word_to_index_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re checking the above results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ewr': 2, 'americanair': 1, 'itinerary': 1, 'be': 1, 'dalla': 1, 'la': 1, 'cancel': 1, 'flightle': 1, 'flight': 1, 'have': 1, 'money': 1, 'find': 1, 'way': 1, 'get': 1, 'there': 1})\n",
      "##Encoding for text no 7 in feature vector is ##\n",
      "americanair 1\n",
      "la 1\n",
      "cancel 1\n",
      "way 1\n",
      "be 1\n",
      "flight 1\n",
      "dalla 1\n",
      "there 1\n",
      "flightle 1\n",
      "money 1\n",
      "find 1\n",
      "have 1\n",
      "itinerary 1\n",
      "ewr 2\n",
      "get 1\n"
     ]
    }
   ],
   "source": [
    "text_no =7\n",
    "message_word_count = Counter(training_messages.iloc[text_no])\n",
    "print(message_word_count)\n",
    "print('##Encoding for text no {} in feature vector is ##'.format(text_no))\n",
    "for i, count in enumerate(training_X[text_no]):\n",
    "    if count >0:\n",
    "        print(index_to_word_dict[i], count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting positive and negative label to 1 and 0  respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11874    negative\n",
       "1986     negative\n",
       "4363     negative\n",
       "4215     positive\n",
       "7737     positive\n",
       "8320     negative\n",
       "10617    negative\n",
       "Name: airline_sentiment, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels.tail(7)# can check from head too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_y = (training_labels.values == 'positive').astype(int)\n",
    "test_y = (test_labels.values == 'positive').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1890, 8192)\n",
      "(8192,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "       0.00011492])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summing up per feature count\n",
    "training_X_positive = training_X[training_y ==1]\n",
    "print(training_X_positive.shape)\n",
    "per_feature_count =np.sum(training_X_positive, axis = 0)\n",
    "print(per_feature_count.shape)\n",
    "\n",
    "np.count_nonzero(per_feature_count)\n",
    "parameters_w_positive = per_feature_count/(np.sum(per_feature_count))\n",
    "\n",
    "parameters_w_positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating parameters for negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7342, 8192)\n",
      "(8192,)\n",
      "[8.99391786e-05 5.62119866e-05 1.12423973e-05 ... 1.12423973e-05\n",
      " 1.12423973e-05 1.23666371e-04]\n"
     ]
    }
   ],
   "source": [
    "training_X_negative = training_X[training_y ==0]\n",
    "print(training_X_negative.shape)\n",
    "per_feature_count =np.sum(training_X_negative, axis = 0)\n",
    "print(per_feature_count.shape)\n",
    "\n",
    "np.count_nonzero(per_feature_count)\n",
    "parameters_w_negative = per_feature_count/(np.sum(per_feature_count))\n",
    "\n",
    "\n",
    "print(parameters_w_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero probability issue\n",
    "As some of the probability can be zero. It will create problem when trying to estimate probability of a new document in test set if that was not in training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One way to handle this situtation to add a fake 1 count of the word in each class called Laplace law of succession or add one smoothing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a class for our multinomial naive bayes and estimate its new parameters based on  Laplace law of succession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multinomial_naive_bayes(object):\n",
    "    \n",
    "    NEGATIVE_CLASS, POSITIVE_CLASS = range(2)\n",
    "    \n",
    "    def __init__(self, class_prior=(.5, .5), fit_prior=True):\n",
    "        \n",
    "        self._class_prior= class_prior\n",
    "        self._fit_prior = fit_prior\n",
    "        \n",
    "        \n",
    "    def fit(self, training_X, training_y):\n",
    "        self.training_X_positive = training_X[training_y ==1]\n",
    "        self.training_X_positive = np.append(self.training_X_positive, np.ones(shape=(1, self.training_X_positive.shape[1])), axis=0)\n",
    "        self.per_feature_count_positive =np.sum(self.training_X_positive, axis = 0)\n",
    "        self._parameters_w_positive = self.per_feature_count_positive/(np.sum(self.per_feature_count_positive))\n",
    "        \n",
    "        self.training_X_negative = training_X[training_y ==0]\n",
    "        self.training_X_negative = np.append(self.training_X_negative, np.ones(shape=(1, self.training_X_negative.shape[1])), axis=0)\n",
    "        self.per_feature_count_negative =np.sum(self.training_X_negative, axis = 0)\n",
    "        self._parameters_w_negative = self.per_feature_count_negative/(np.sum(self.per_feature_count_negative))\n",
    "        \n",
    "        if self._fit_prior:\n",
    "            self._class_prior = self._calculate_prior(len(self.training_X_positive), len(self.training_X_negative))\n",
    "         \n",
    "    def _calculate_prior(self, n_positive, n_negative):    \n",
    "        positive_prior = n_positive/(n_positive + n_negative)\n",
    "        negative_prior = 1- positive_prior\n",
    "        return negative_prior,positive_prior\n",
    "        #raise NotImplementedError(\"implement this!\")\n",
    "        \n",
    "        \n",
    "    def _calculate_score(self, parameters,test_text, class_prior):\n",
    "            return np.sum(np.log(np.power(parameters,test_text))) + class_prior            \n",
    "        \n",
    "    def predict(self, test_X, test_y):\n",
    "        self.positive_score = np.zeros_like(test_y,dtype=float)\n",
    "        self.negative_score = np.zeros_like(test_y,dtype=float)\n",
    "\n",
    "        for idx, test_text in enumerate(test_X):# this will fetch row by row, encoded test messages\n",
    "            self.positive_score[idx] = self._calculate_score(self._parameters_w_positive,\n",
    "                                                        test_text,\n",
    "                                                        np.log(self._class_prior[multinomial_naive_bayes.POSITIVE_CLASS]))\n",
    "            self.negative_score[idx] = self._calculate_score(self._parameters_w_negative,\n",
    "                                                        test_text, np.log(self._class_prior[multinomial_naive_bayes.NEGATIVE_CLASS]))\n",
    "\n",
    "       # predict the label positive(1) or negative(0)\n",
    "        positive_or_negative = (self.positive_score >= self.negative_score).astype(int)\n",
    "        accuracy= np.sum(positive_or_negative == test_y) / len(positive_or_negative)\n",
    "        return accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = multinomial_naive_bayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(training_X, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9060199220441749"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing using MultinomialNB classifer  from sklearn and report accuracy in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9060199220441749"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(training_X, training_y)\n",
    "ypred= classifier.predict(test_X)\n",
    "classifier.score(test_X, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
